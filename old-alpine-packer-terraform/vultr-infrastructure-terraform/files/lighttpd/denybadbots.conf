# Block some (usually) malicious traffic

# Empty UA, or -
$HTTP["useragent"] == "" { url.access-deny = ( "" ) accesslog.filename = "/var/log/lighttpd/spam.log" url.redirect = ( "" => "https://radicale-lighttpd-01.wildtechgarden.ca/robots.txt" ) }
$HTTP["useragent"] == "-" { url.access-deny = ( "" ) accesslog.filename = "/var/log/lighttpd/spam.log"  }
$HTTP["useragent"] =~ "^ +$" {url.access-deny = ( "" ) accesslog.filename = "/var/log/lighttpd/spam.log" url.redirect = ( "" => "https://radicale-lighttpd-01.wildtechgarden.ca/robots.txt" ) }

# Block bad requests with empty "Host" headers.
$HTTP["host"] == "" {url.access-deny = ( "" ) accesslog.filename = "/var/log/lighttpd/spam.log" url.redirect = ( "" => "https://radicale-lighttpd-01.wildtechgarden.ca/robots.txt" ) }
$HTTP["host"] =~ "^ +$" {url.access-deny = ( "" ) accesslog.filename = "/var/log/lighttpd/spam.log" url.redirect = ( "" => "https://radicale-lighttpd-01.wildtechgarden.ca/robots.txt" ) }
$HTTP["host"] == "-" { url.access-deny = ( "" ) accesslog.filename = "/var/log/lighttpd/spam.log" url.redirect = ( "" => "https://radicale-lighttpd-01.wildtechgarden.ca/robots.txt" ) }

# Request for git.xxx gitea.xxx are likely bots
$HTTP["host"] =~ "^git" { url.access-deny = ( "" ) accesslog.filename = "/var/log/lighttpd/spam.log" url.redirect = ( "" => "https://radicale-lighttpd-01.wildtechgarden.ca/robots.txt" ) }

# Block requests by IP; not likely to be legitimate traffic
$HTTP["host"] =~ "^52\.229\.71\.196(:(80|443))?" {url.access-deny = ( "" ) accesslog.filename = "/var/log/lighttpd/spam.log" url.redirect = ( "" => "https://radicale-lighttpd-01.wildtechgarden.ca/robots.txt" ) }

# Deny all URLs to likely malicious UAs (minimizing access to potentially vulnerable apps).
$HTTP["useragent"] =~ "\/var\/|\/tmp\/|\/etc\/|China\.Z|ZmEu|Zollard|gawa\.sa\.pilipinas|Jorgee" { url.access-deny = ( "" ) accesslog.filename = "/var/log/lighttpd/spam.log" url.redirect = ( "" => "https://radicale-lighttpd-01.wildtechgarden.ca/robots.txt" ) }

# Block bots I actually see and are a problem
$HTTP["useragent"] =~ "petalbot|PetalBot|MJ12bot|zgrab|Mozlila|centryb\.o\.t|netcraft|Barkrowler|BLEXBot|Bulid" { url.access-deny = ( "" ) accesslog.filename = "/var/log/lighttpd/spam.log" url.redirect = ( "" => "https://radicale-lighttpd-01.wildtechgarden.ca/robots.txt" ) }

# Block URLs that are certainly attempts at malicious behaviour
$HTTP["url"] =~ "/wp-login/|\.env|xmlrpc|autodiscover|/wp-content/|cgi-bin|/wordpress/|ThinkPHP|phpunit|^\.git|/add/|phpinfo|_ignition|evox|oauth|phpstorm|solr|\.aws|aws\.yml|/rss|/admin|ckeditor|kcfinder|/wlmanifest.xml|eval-stdin|\.php$" { url.access-deny = ( "" ) accesslog.filename = "/var/log/lighttpd/spam.log" url.redirect = ( "" => "https://radicale-lighttpd-01.wildtechgarden.ca/robots.txt" ) }

# Queries that are likely malicious
$HTTP["querystring"] =~ "XDEBUG_SESSION_START|HelloThinkCMF|ThinkPHP" { url.access-deny = ( "" ) accesslog.filename = "/var/log/lighttpd/spam.log" url.redirect = ( "" => "https://radicale-lighttpd-01.wildtechgarden.ca/robots.txt" ) }

# Block all but GET, HEAD, PRI methods
$HTTP["request-method"] !~ "HEAD|GET|PRI" { url.access-deny = ( "" ) accesslog.filename = "/var/log/lighttpd/spam.log" url.redirect = ( "" => "https://radicale-lighttpd-01.wildtechgarden.ca/robots.txt" ) }

# Always allow access to robots.txt, to everyone.
$HTTP["url"] =~ "^/robots.txt" {
    url.access-deny = ("disable")
    # For bad bots use the local robots.txt, which sets disallow all
    $HTTP["scheme"] == "https" {
        $HTTP["host"] == "radicale-lighttpd-01.wildtechgarden.ca" { url.redirect = ( "" => "" ) }
    }
}
